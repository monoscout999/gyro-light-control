# üéØ Project Vision: 3D Gyroscope Pointer for Moving Lights Control

**Project Code**: GYRO-LIGHT-CONTROL  
**Created**: 2024-12-15  
**Status**: PLANNING PHASE  
**Lead Developer**: User  

---

## üìã Executive Summary

Application that uses mobile device gyroscope sensors to create a 3D pointer in virtual space, enabling intuitive calibration and control of professional moving lights (stage lighting fixtures).

---

## üé≠ Core Concept

**The Problem**: Calibrating moving stage lights' positions is tedious and requires multiple people or complex interfaces.

**The Solution**: Point your phone at where you want the light to aim ‚Üí the light moves there.

---

## üèóÔ∏è Technical Architecture

### **Platform Stack**
- **Desktop Application**: Python-based server
  - Creates local web server
  - Handles 3D simulation/visualization
  - Manages DMX output via ArtNet protocol
  - Central control hub

- **Mobile Interface**: Web-based (responsive HTML/CSS/JS)
  - Accessed via browser (no app installation needed)
  - Streams gyroscope data to server
  - Minimal UI: pointer visual + calibration buttons
  - Connection via local network

### **Communication Flow**
```
[Mobile Browser] ‚Üê‚Üí [Python Server] ‚Üê‚Üí [DMX/ArtNet] ‚Üê‚Üí [Moving Lights]
     WebSocket          Processing           Network         Hardware
```

---

## üéÆ User Workflow (Target Experience)

### Phase 1: Setup
1. User runs Python desktop app
2. Desktop shows: server URL (e.g., `http://192.168.1.10:8080`)
3. User opens that URL on mobile browser
4. Mobile connects, shows "READY" status

### Phase 2: Calibration
1. User stands at **venue center** (configurable, default: 10x10m venue, user at 5,5)
2. User aims phone at **back wall center**
3. User presses **"CALIBRATE"** button on mobile
4. System establishes coordinate reference frame
5. ‚ö†Ô∏è **CRITICAL CHALLENGE**: This is where mathematical complexity begins (deferred to detailed docs)

### Phase 3: Operation
1. User points phone in any direction
2. Desktop shows pointer in 3D space
3. Selected moving light follows pointer (Phase 2 feature)

---

## üìê Coordinate System (High-Level)

- **Venue**: Configurable XYZ space (default: 10m √ó 10m √ó height)
- **Origin**: User-defined center point (default: 5, 5, 0)
- **Calibration Reference**: Back wall center
- **Mobile Orientation**: Raw gyroscope ‚Üí quaternions/euler angles ‚Üí 3D vector

**‚ö†Ô∏è DEFERRED**: Detailed mathematical formulas documented separately in `02_validated_formulas.md`

---

## üéØ Development Phases (MVP Strategy)

### **PHASE 0: 3D Visualizer (Standalone Debug Tool)** ‚úã **‚Üê START HERE**
**Goal**: Build comprehensive visualization and testing tool FIRST

**Deliverables**:
- ‚úÖ Python desktop app (FastAPI backend + Three.js frontend)
- ‚úÖ 3D viewport showing venue (10√ó10√ó4m configurable)
- ‚úÖ READ-ONLY sliders displaying alpha/beta/gamma from sensor data
- ‚úÖ Pointer visualization (laser ray + intersection point)
- ‚úÖ 1 moving light fixture with automatic following
- ‚úÖ Properties panel (venue, fixture, user configuration)
- ‚úÖ Debug console with filters
- ‚úÖ Manual calibration system
- ‚úÖ Save/load scene configurations
- ‚úÖ Simple fixture creation interface

**Success Criteria**:
- Receive sensor data from mobile ‚Üí see pointer move in 3D
- Calibration locks pointer to back wall center
- Fixture follows pointer automatically
- Can save and reload complete scenes

---

### **PHASE 1: Real Sensor Integration** 
**Goal**: Connect real mobile gyroscope to visualizer

**Deliverables**:
- ‚úÖ Mobile web interface (sensor access)
- ‚úÖ WebSocket streaming to visualizer
- ‚úÖ Real-time data flow with latency buffer
- ‚úÖ Smooth pointer movement (<100ms latency)

**Success Criteria**: 
- Point phone ‚Üí see pointer move in 3D space smoothly
- Calibration works with real device
- System handles network latency gracefully

---

### **PHASE 2: Light Control** ‚è∏Ô∏è **‚Üê LATER**
**Goal**: Connect to real hardware

**Deliverables**:
- ‚úÖ DMX/ArtNet output working
- ‚úÖ Library for various light models (generic + custom)
- ‚úÖ Pointer ‚Üí Pan/Tilt translation
- ‚úÖ Multi-light support
- ‚úÖ Save/load configurations

**Success Criteria**:
- Point phone ‚Üí light physically moves to that position

---

## üö´ What This Document Does NOT Cover

These are intentionally deferred to specialized documents:

- ‚ùå Detailed gyroscope math formulas ‚Üí `02_validated_formulas.md`
- ‚ùå DMX/ArtNet protocol specifics ‚Üí `03_module_architecture.md`
- ‚ùå UI/UX design details ‚Üí `03_module_architecture.md`
- ‚ùå Code implementation ‚Üí `/src/` directory
- ‚ùå Calibration algorithm details ‚Üí `02_validated_formulas.md`

---

## üß† Development Philosophy (CRITICAL)

### **Why This Project Failed Before**

**Problem**: Working with AI agents on long sessions led to:
1. ‚úÖ Solution A works ‚Üí implement Solution B ‚Üí Solution A breaks
2. Mathematical formulas "drift" between versions
3. Context contamination (mixing unrelated features)
4. No "source of truth" for validated code

### **The Solution: Multi-Agent Modular Architecture**

**Core Principle**: 
> "No single agent has the full context. Each agent owns one domain. A Registrar Agent maintains the master state."

**Agent Roles**:
1. **Registrar Agent** (Documentation custodian)
   - NO CODE GENERATION
   - Maintains decision logs
   - Marks validated code as immutable
   - Generates clean contexts for other agents

2. **Prompt Engineer Agent** (Context preparer)
   - Prevents contamination
   - Creates focused prompts for specialists
   
3. **Math Agent** (Sensor/3D calculations)
   - Owns gyroscope formulas
   - 3D transformations
   - Calibration algorithms

4. **Backend Agent** (Python server)
   - Server architecture
   - WebSocket handling
   - DMX output

5. **Frontend Agent** (Mobile UI)
   - Web interface
   - Sensor access
   - Real-time updates

**Protocol**:
- Each coding session starts with Registrar providing context
- After validation, code marked `[VALIDADO-{date}]`
- Validated code CANNOT be modified without explicit approval
- All decisions logged with rationale

---

## üìä Success Metrics

**Phase 1 Complete When**:
- [ ] Server runs without errors
- [ ] Mobile connects reliably
- [ ] 3D visualization responsive (<100ms latency)
- [ ] Calibration reproducible (same result on repeated attempts)
- [ ] Code is modular and documented

**Phase 2 Complete When**:
- [ ] At least 1 real moving light controlled successfully
- [ ] Pointer-to-light accuracy within ¬±5¬∞ (acceptable for stage use)
- [ ] Configuration save/load works
- [ ] Multi-light support functional

---

## üîí Immutability Rules

**This Document Cannot Change**:
- Core concept (gyroscope ‚Üí 3D pointer ‚Üí light control)
- Phase 1 before Phase 2 ordering
- Multi-agent architecture principle
- Technology stack (Python + Web)

**This Document Can Evolve**:
- Venue size defaults
- Exact protocols (as long as DMX/ArtNet compatible)
- Additional phases beyond Phase 2
- Non-breaking refinements

---

## üìù Related Documents (To Be Created)

- `01_technical_requirements.md` - Detailed specs
- `02_validated_formulas.md` - Math that WORKS
- `03_module_architecture.md` - Code structure
- `04_decision_log.md` - Why we chose X over Y
- `05_agent_protocols.md` - How to interact with each agent

---

## üé¨ Next Steps (When Development Starts)

1. **Create remaining documentation** (with Registrar Agent)
2. **Design Phase 1 architecture** (modular structure)
3. **Prototype sensor streaming** (simplest possible version)
4. **Validate core math** (quaternion ‚Üí vector transform)
5. **Build 3D visualization** (Three.js or similar)
6. **Integrate & test** (end-to-end Phase 1)

---

## üí° Developer Notes

**When returning to this project**:
- Read this document first (5 min)
- Check `04_decision_log.md` for latest state
- Consult `02_validated_formulas.md` before touching math
- Never modify `[VALIDADO]` code without Registrar review

**When stuck**:
- Return to this vision
- Is the problem blocking Phase 1 or Phase 2?
- Can it be deferred?
- Is there a simpler approach?

---

**END OF VISION DOCUMENT**

*This is the anchor. Everything else is implementation detail.*
